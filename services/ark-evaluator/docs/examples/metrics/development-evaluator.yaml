## Development environment evaluator with relaxed thresholds
apiVersion: ark.mckinsey.com/v1alpha1
kind: Evaluator
metadata:
  name: development-metrics-evaluator
  namespace: default
  labels:
    type: development-metrics
    category: dev-environment
    environment: development
spec:
  description: "Development environment evaluator with relaxed thresholds for testing"
  address:
    valueFrom:
      serviceRef:
        name: evaluator-metric
        port: "http"
        path: "/evaluate/direct"
  selector:
    resourceType: "Query"
    apiGroup: "ark.mckinsey.com"
    matchLabels:
      environment: "development"
    matchExpressions:
      - key: team
        operator: In
        values: ["dev", "qa", "staging"]
  parameters:
    - name: maxTokens
      value: "10000"  # Higher for development/testing
    - name: maxDuration
      value: "1s"     # More relaxed timing
    - name: maxCostPerQuery
      value: "1.00"   # Higher cost limit for experimentation
    - name: tokenEfficiencyThreshold
      value: "0.3"    # Lower efficiency requirements
    - name: costEfficiencyThreshold
      value: "0.4"
    - name: performanceThreshold
      value: "0.5"
    - name: overallScoreThreshold
      value: "0.4"    # Much lower passing threshold
    - name: enableDetailedLogging
      value: "true"   # Extra logging for development
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: development-config
  namespace: default
data:
  # Development-specific settings
  debug-mode: "true"
  verbose-logging: "true"
  metric-collection-interval: "1s"
  
  # Relaxed thresholds for different teams
  dev-team-maxTokens: "15000"
  qa-team-maxTokens: "12000"
  staging-team-maxTokens: "8000"
  
  # Alert thresholds (higher for dev)
  token-warning-threshold: "8000"
  cost-warning-threshold: "0.75"
  duration-warning-threshold: "90s"